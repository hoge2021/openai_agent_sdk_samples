import asyncio
import os
from typing import Any, List
from dataclasses import dataclass
from openai import OpenAI
from agents import Agent, Runner, RunContextWrapper, FileSearchTool, function_tool
from agents.models import OpenAIResponsesModel

# ========================================
# 1. ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®è¨­å®šã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ========================================

def setup_vector_store(api_key: str) -> str:
    """
    ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½œæˆã—ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
    
    Returns:
        str: ä½œæˆã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ID
    """
    client = OpenAI(api_key=api_key)
    
    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ä½œæˆ
    vector_store = client.beta.vector_stores.create(
        name="æŠ€è¡“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢",
        description="æŠ€è¡“æ–‡æ›¸ã‚„ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’ä¿å­˜ã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢"
    )
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã®ä½¿ç”¨æ™‚ã¯é©åˆ‡ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã«å¤‰æ›´ï¼‰
    file_paths = [
        "documents/technical_manual.pdf",
        "documents/api_reference.md",
        "documents/user_guide.txt"
    ]
    
    file_ids = []
    for file_path in file_paths:
        if os.path.exists(file_path):
            with open(file_path, "rb") as file:
                uploaded_file = client.files.create(
                    file=file,
                    purpose="assistants"
                )
                file_ids.append(uploaded_file.id)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«è¿½åŠ 
    if file_ids:
        client.beta.vector_stores.files.create_batch(
            vector_store_id=vector_store.id,
            file_ids=file_ids
        )
    
    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®å‡¦ç†ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
    import time
    while True:
        vector_store_status = client.beta.vector_stores.retrieve(vector_store.id)
        if vector_store_status.status == "completed":
            break
        time.sleep(1)
    
    return vector_store.id


# ========================================
# 2. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹
# ========================================

@dataclass
class RAGContext:
    """RAGã‚·ã‚¹ãƒ†ãƒ ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’ä¿æŒ"""
    user_id: str
    session_id: str
    vector_store_ids: List[str]
    search_history: List[dict] = None
    
    def __post_init__(self):
        if self.search_history is None:
            self.search_history = []


# ========================================
# 3. ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«é–¢æ•°ã®å®šç¾©
# ========================================

@function_tool
async def analyze_search_results(
    ctx: RunContextWrapper[RAGContext],
    query: str,
    results: str
) -> str:
    """
    æ¤œç´¢çµæœã‚’åˆ†æã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸå›ç­”ã‚’ç”Ÿæˆã™ã‚‹
    
    Args:
        ctx: å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒª
        results: æ¤œç´¢çµæœ
    
    Returns:
        str: æ§‹é€ åŒ–ã•ã‚ŒãŸåˆ†æçµæœ
    """
    # æ¤œç´¢å±¥æ­´ã«è¿½åŠ 
    ctx.context.search_history.append({
        "query": query,
        "results": results,
        "timestamp": __import__("datetime").datetime.now().isoformat()
    })
    
    # çµæœã‚’åˆ†æï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚ˆã‚Šé«˜åº¦ãªåˆ†æã‚’è¡Œã†ï¼‰
    analysis = f"""
    ## æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}
    
    ### æ¤œç´¢çµæœã®åˆ†æ:
    - é–¢é€£æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ
    - ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {ctx.context.session_id}
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {ctx.context.user_id}
    
    ### è©³ç´°æƒ…å ±:
    {results}
    """
    
    return analysis


@function_tool
async def get_additional_context(
    ctx: RunContextWrapper[RAGContext],
    topic: str
) -> str:
    """
    ç‰¹å®šã®ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    
    Args:
        ctx: å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        topic: æ¤œç´¢ã™ã‚‹ãƒˆãƒ”ãƒƒã‚¯
    
    Returns:
        str: è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
    """
    # å®Ÿéš›ã®å®Ÿè£…ã§ã¯å¤–éƒ¨APIã‚„åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
    additional_info = f"""
    ãƒˆãƒ”ãƒƒã‚¯ã€Œ{topic}ã€ã«é–¢ã™ã‚‹è¿½åŠ æƒ…å ±:
    - æœ€çµ‚æ›´æ–°: 2024å¹´12æœˆ
    - é–¢é€£ãƒˆãƒ”ãƒƒã‚¯: APIè¨­è¨ˆã€ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    - å‚ç…§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(ctx.context.vector_store_ids)}
    """
    
    return additional_info


# ========================================
# 4. RAG Agentã®å®Ÿè£…
# ========================================

def create_rag_agent(
    vector_store_ids: List[str],
    context: RAGContext
) -> Agent[RAGContext]:
    """
    FileSearchToolã‚’ä½¿ç”¨ã—ãŸRAG Agentã‚’ä½œæˆ
    
    Args:
        vector_store_ids: æ¤œç´¢å¯¾è±¡ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ID
        context: RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    
    Returns:
        Agent: è¨­å®šæ¸ˆã¿ã®RAG Agent
    """
    
    # å‹•çš„ãªæŒ‡ç¤ºã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
    def dynamic_instructions(ctx: RunContextWrapper[RAGContext]) -> str:
        return f"""
        ã‚ãªãŸã¯é«˜åº¦ãªRAGã‚·ã‚¹ãƒ†ãƒ ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
        
        ## ã‚ãªãŸã®å½¹å‰²:
        1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’ç†è§£ã—ã€é–¢é€£æƒ…å ±ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‹ã‚‰æ¤œç´¢ã™ã‚‹
        2. æ¤œç´¢çµæœã‚’åˆ†æã—ã€æ­£ç¢ºã§æœ‰ç”¨ãªå›ç­”ã‚’æä¾›ã™ã‚‹
        3. å¿…è¦ã«å¿œã˜ã¦è¿½åŠ ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹
        
        ## ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±:
        - ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {ctx.context.user_id}
        - ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {ctx.context.session_id}
        - æ¤œç´¢å±¥æ­´æ•°: {len(ctx.context.search_history)}
        
        ## å›ç­”æ–¹é‡:
        - æ¤œç´¢çµæœã«åŸºã¥ã„ã¦æ­£ç¢ºã«å›ç­”ã™ã‚‹
        - æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜ç¢ºã«ä¼ãˆã‚‹
        - æŠ€è¡“çš„ãªå†…å®¹ã¯åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã™ã‚‹
        """
    
    # FileSearchToolã®è¨­å®š
    file_search_tool = FileSearchTool(
        vector_store_ids=vector_store_ids,
        max_num_results=5,  # æœ€å¤§5ä»¶ã®çµæœã‚’å–å¾—
        include_search_results=True,  # LLMã®å‡ºåŠ›ã«æ¤œç´¢çµæœã‚’å«ã‚ã‚‹
        ranking_options={
            "ranker": "default_2024_08_21",  # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
            "score_threshold": 0.0  # ã‚¹ã‚³ã‚¢ã—ãã„å€¤
        }
    )
    
    # Agentã®ä½œæˆ
    agent = Agent[RAGContext](
        name="RAG Assistant",
        instructions=dynamic_instructions,
        tools=[
            file_search_tool,
            analyze_search_results,
            get_additional_context
        ],
        model=OpenAIResponsesModel(model="gpt-4o-mini")
    )
    
    return agent


# ========================================
# 5. é«˜åº¦ãªRAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
# ========================================

class AdvancedRAGPipeline:
    """é«˜åº¦ãªRAGå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.client = OpenAI(api_key=api_key)
        self.vector_store_ids = []
    
    async def initialize(self, documents: List[str] = None):
        """
        ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åˆæœŸåŒ–
        
        Args:
            documents: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆ
        """
        if documents:
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            vector_store_id = setup_vector_store(self.api_key)
            self.vector_store_ids.append(vector_store_id)
    
    async def search_and_respond(
        self,
        query: str,
        user_id: str = "default_user",
        session_id: str = None
    ) -> str:
        """
        ã‚¯ã‚¨ãƒªã‚’å‡¦ç†ã—ã€RAGã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
        
        Args:
            query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒª
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
        
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸå¿œç­”
        """
        if session_id is None:
            import uuid
            session_id = str(uuid.uuid4())
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä½œæˆ
        context = RAGContext(
            user_id=user_id,
            session_id=session_id,
            vector_store_ids=self.vector_store_ids
        )
        
        # Agentã®ä½œæˆ
        agent = create_rag_agent(self.vector_store_ids, context)
        
        # ã‚¯ã‚¨ãƒªã®å®Ÿè¡Œ
        result = await Runner.run(
            starting_agent=agent,
            input=query,
            context=context
        )
        
        return result.final_output
    
    async def multi_turn_conversation(
        self,
        queries: List[str],
        user_id: str = "default_user"
    ):
        """
        ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ä¼šè©±ã‚’å‡¦ç†
        
        Args:
            queries: ã‚¯ã‚¨ãƒªã®ãƒªã‚¹ãƒˆ
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
        """
        import uuid
        session_id = str(uuid.uuid4())
        
        context = RAGContext(
            user_id=user_id,
            session_id=session_id,
            vector_store_ids=self.vector_store_ids
        )
        
        agent = create_rag_agent(self.vector_store_ids, context)
        
        conversation_history = []
        
        for query in queries:
            print(f"\nğŸ‘¤ User: {query}")
            
            # å‰å›ã®ä¼šè©±å±¥æ­´ã‚’å«ã‚ã¦ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
            if conversation_history:
                full_query = f"ä»¥å‰ã®ä¼šè©±ã‚’è€ƒæ…®ã—ã¦å›ç­”ã—ã¦ãã ã•ã„:\n{query}"
            else:
                full_query = query
            
            result = await Runner.run(
                starting_agent=agent,
                input=full_query,
                context=context
            )
            
            response = result.final_output
            print(f"ğŸ¤– Assistant: {response}")
            
            conversation_history.append({
                "query": query,
                "response": response
            })
        
        return conversation_history


# ========================================
# 6. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨åˆ†
# ========================================

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    # API ã‚­ãƒ¼ã®è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    # RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åˆæœŸåŒ–
    pipeline = AdvancedRAGPipeline(api_key)
    
    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®åˆæœŸåŒ–ï¼ˆå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆï¼‰
    # await pipeline.initialize(documents=["path/to/doc1.pdf", "path/to/doc2.md"])
    
    # å˜ä¸€ã‚¯ã‚¨ãƒªã®å®Ÿè¡Œä¾‹
    print("=" * 50)
    print("ğŸ“š RAGã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¢ - å˜ä¸€ã‚¯ã‚¨ãƒª")
    print("=" * 50)
    
    single_query = "APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"
    response = await pipeline.search_and_respond(single_query)
    print(f"\nè³ªå•: {single_query}")
    print(f"å›ç­”: {response}")
    
    # ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã®ä¾‹
    print("\n" + "=" * 50)
    print("ğŸ’¬ RAGã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¢ - ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±")
    print("=" * 50)
    
    queries = [
        "ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¦‚è¦ã‚’æ•™ãˆã¦ãã ã•ã„",
        "ãã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã¯ï¼Ÿ",
        "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æœ€é©åŒ–æ–¹æ³•ã«ã¤ã„ã¦ã‚‚æ•™ãˆã¦ãã ã•ã„"
    ]
    
    await pipeline.multi_turn_conversation(queries)
    
    print("\nâœ… ãƒ‡ãƒ¢å®Œäº†")


# ========================================
# 7. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãå®Ÿè¡Œ
# ========================================

async def run_with_error_handling():
    """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å«ã‚€å®Ÿè¡Œ"""
    try:
        await main()
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®å®Ÿè¡Œ
    asyncio.run(run_with_error_handling())