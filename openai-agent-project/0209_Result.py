#!/usr/bin/env python3
"""
OpenAI Agents SDK - Resultå„è¦ç´  ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
"""

import asyncio
import os
import sys
import datetime
import json
from dataclasses import dataclass
from typing import Any, List

# OpenAI Agents SDK ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from pydantic import BaseModel
    from agents import (
        Agent,
        Runner,
        RunContextWrapper,
        function_tool,
        handoff,
        input_guardrail,
        output_guardrail,
        GuardrailFunctionOutput,
        InputGuardrailTripwireTriggered,
        OutputGuardrailTripwireTriggered,
    )
    from agents.items import (
        RunItem, 
        MessageOutputItem, 
        ToolCallItem, 
        ToolCallOutputItem,
        HandoffCallItem,
        HandoffOutputItem
    )
except ImportError:
    print("âŒ ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install openai-agents pydantic")
    sys.exit(1)


# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å®šç¾©
@dataclass
class UserContext:
    user_id: str
    session_id: str
    conversation_history: List[str]


# å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
class TaskResponse(BaseModel):
    content: str
    category: str
    confidence: float
    timestamp: str


class AnalysisResponse(BaseModel):
    analysis: str
    recommendations: List[str]
    urgency_level: str


# ãƒ„ãƒ¼ãƒ«é–¢æ•°ç¾¤
@function_tool
def get_current_time() -> str:
    """ç¾åœ¨ã®æ—¥æ™‚ã‚’å–å¾—ã™ã‚‹"""
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")


@function_tool
def analyze_text(text: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆã®ç°¡å˜ãªåˆ†æã‚’è¡Œã†"""
    word_count = len(text.split())
    char_count = len(text)
    
    # æ„Ÿæƒ…åˆ†æï¼ˆç°¡æ˜“ç‰ˆï¼‰
    positive_words = ["è‰¯ã„", "ç´ æ™´ã‚‰ã—ã„", "æœ€é«˜", "å¬‰ã—ã„", "ã‚ã‚ŠãŒã¨ã†", "good", "great", "excellent"]
    negative_words = ["æ‚ªã„", "æœ€æ‚ª", "æ®‹å¿µ", "å›°ã£ãŸ", "å•é¡Œ", "bad", "terrible", "awful"]
    
    positive_count = sum(1 for word in positive_words if word in text.lower())
    negative_count = sum(1 for word in negative_words if word in text.lower())
    
    if positive_count > negative_count:
        sentiment = "ãƒã‚¸ãƒ†ã‚£ãƒ–"
    elif negative_count > positive_count:
        sentiment = "ãƒã‚¬ãƒ†ã‚£ãƒ–"
    else:
        sentiment = "ä¸­æ€§"
    
    return f"åˆ†æçµæœ: æ–‡å­—æ•°={char_count}, å˜èªæ•°={word_count}, æ„Ÿæƒ…={sentiment} (P:{positive_count}, N:{negative_count})"


@function_tool
def generate_recommendation(context: str) -> str:
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆã™ã‚‹"""
    recommendations = [
        "è©³ç´°ãªåˆ†æãŒå¿…è¦ã§ã™",
        "è¿½åŠ æƒ…å ±ã®åé›†ã‚’ãŠå‹§ã‚ã—ã¾ã™",
        "å°‚é–€å®¶ã¨ã®ç›¸è«‡ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
        "æ®µéšçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å–ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™"
    ]
    
    import random
    selected = random.sample(recommendations, min(2, len(recommendations)))
    return f"æ¨å¥¨äº‹é …: {', '.join(selected)}"


# Guardrailé–¢æ•°
@input_guardrail
async def input_logger_guardrail(ctx, agent, input_data) -> GuardrailFunctionOutput:
    """å…¥åŠ›ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹Guardrail"""
    timestamp = datetime.datetime.now().isoformat()
    input_text = str(input_data)
    
    log_info = {
        "timestamp": timestamp,
        "agent": agent.name,
        "user_id": ctx.context.user_id,
        "input_length": len(input_text),
        "input_preview": input_text[:50] + "..." if len(input_text) > 50 else input_text
    }
    
    print(f"ğŸ“ [Input Guardrail] ãƒ­ã‚°è¨˜éŒ²: {log_info}")
    
    return GuardrailFunctionOutput(
        output_info=log_info,
        tripwire_triggered=False
    )


@output_guardrail
async def output_validator_guardrail(ctx, agent, output) -> GuardrailFunctionOutput:
    """å‡ºåŠ›ã‚’æ¤œè¨¼ã™ã‚‹Guardrail"""
    validation_info = {
        "agent_name": agent.name,
        "output_type": type(output).__name__,
        "has_content": hasattr(output, 'content') and bool(getattr(output, 'content', '')),
        "validation_time": datetime.datetime.now().isoformat()
    }
    
    print(f"âœ… [Output Guardrail] æ¤œè¨¼å®Œäº†: {validation_info}")
    
    return GuardrailFunctionOutput(
        output_info=validation_info,
        tripwire_triggered=False
    )


def check_api_key():
    """OpenAI API ã‚­ãƒ¼ã®å­˜åœ¨ç¢ºèª"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("ä»¥ä¸‹ã®æ–¹æ³•ã§è¨­å®šã—ã¦ãã ã•ã„:")
        print("  Linux/Mac: export OPENAI_API_KEY='your-api-key-here'")
        print("  Windows: set OPENAI_API_KEY=your-api-key-here")
        return False
    
    if not api_key.startswith("sk-"):
        print("âš ï¸  è­¦å‘Š: API ã‚­ãƒ¼ã®å½¢å¼ãŒæ­£ã—ããªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        print("OpenAI API ã‚­ãƒ¼ã¯é€šå¸¸ 'sk-' ã§å§‹ã¾ã‚Šã¾ã™ã€‚")
    
    print("âœ… API ã‚­ãƒ¼ãŒæ­£å¸¸ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã™")
    return True


def analyze_run_items(new_items: List[RunItem]):
    """RunItemã®è©³ç´°åˆ†æ"""
    print("\nğŸ” Run Items è©³ç´°åˆ†æ:")
    print("-" * 60)
    
    item_counts = {}
    
    for i, item in enumerate(new_items):
        item_type = item.type
        item_counts[item_type] = item_counts.get(item_type, 0) + 1
        
        print(f"ğŸ“‹ Item {i+1}: {item_type}")
        
        if item_type == "message_output_item":
            # MessageOutputItem ã®è©³ç´°
            if hasattr(item, 'raw_item') and hasattr(item.raw_item, 'content'):
                content = str(item.raw_item.content)[:100]
                print(f"   ğŸ’¬ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {content}{'...' if len(str(item.raw_item.content)) > 100 else ''}")
                
        elif item_type == "tool_call_item":
            # ToolCallItem ã®è©³ç´°
            if hasattr(item, 'tool_name'):
                print(f"   ğŸ”§ ãƒ„ãƒ¼ãƒ«å: {item.tool_name}")
            if hasattr(item, 'raw_item') and hasattr(item.raw_item, 'function'):
                args = getattr(item.raw_item.function, 'arguments', 'N/A')
                print(f"   ğŸ“¥ å¼•æ•°: {args}")
                
        elif item_type == "tool_call_output_item":
            # ToolCallOutputItem ã®è©³ç´°
            if hasattr(item, 'output'):
                output_preview = str(item.output)[:80]
                print(f"   ğŸ“¤ å‡ºåŠ›: {output_preview}{'...' if len(str(item.output)) > 80 else ''}")
                
        elif item_type == "handoff_call_item":
            # HandoffCallItem ã®è©³ç´°
            print(f"   ğŸ”„ ãƒãƒ³ãƒ‰ã‚ªãƒ•å‘¼ã³å‡ºã—")
            
        elif item_type == "handoff_output_item":
            # HandoffOutputItem ã®è©³ç´°
            if hasattr(item, 'source_agent') and hasattr(item, 'target_agent'):
                print(f"   ğŸ”„ ãƒãƒ³ãƒ‰ã‚ªãƒ•: {item.source_agent.name} â†’ {item.target_agent.name}")
    
    print(f"\nğŸ“Š ã‚¢ã‚¤ãƒ†ãƒ çµ±è¨ˆ:")
    for item_type, count in item_counts.items():
        print(f"   {item_type}: {count}å€‹")


async def demonstrate_basic_result_analysis(user_context: UserContext):
    """åŸºæœ¬çš„ãªResultåˆ†æã®ãƒ‡ãƒ¢"""
    print("\n" + "="*80)
    print("ğŸ“Š 1. åŸºæœ¬çš„ãªResultåˆ†æãƒ‡ãƒ¢")
    print("="*80)
    
    # åŸºæœ¬Agent
    basic_agent = Agent[UserContext](
        name="Basic Analyzer",
        instructions=(
            "ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã®å°‚é–€å®¶ã¨ã—ã¦ã€å…¥åŠ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è©³ç´°ã«åˆ†æã—ã€"
            "æ§‹é€ åŒ–ã•ã‚ŒãŸçµæœã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"
        ),
        model="gpt-4o-mini",
        tools=[analyze_text, get_current_time],
        output_type=TaskResponse,
        input_guardrails=[input_logger_guardrail],
        output_guardrails=[output_validator_guardrail],
    )
    
    test_input = "ä»Šæ—¥ã¯ç´ æ™´ã‚‰ã—ã„å¤©æ°—ã§ã™ã­ï¼ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®å‹‰å¼·ãŒæ—ã‚Šãã†ã§ã™ã€‚"
    
    try:
        print(f"ğŸ“ å…¥åŠ›: ã€Œ{test_input}ã€")
        print("-" * 50)
        
        result = await Runner.run(
            starting_agent=basic_agent,
            input=test_input,
            context=user_context,
            max_turns=5
        )
        
        # === 1. final_output ã®åˆ†æ ===
        print(f"ğŸ¯ final_output åˆ†æ:")
        print(f"   ã‚¿ã‚¤ãƒ—: {type(result.final_output).__name__}")
        if hasattr(result.final_output, 'content'):
            print(f"   å†…å®¹: {result.final_output.content}")
            print(f"   ã‚«ãƒ†ã‚´ãƒª: {result.final_output.category}")
            print(f"   ä¿¡é ¼åº¦: {result.final_output.confidence}")
            print(f"   ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {result.final_output.timestamp}")
        else:
            print(f"   å€¤: {result.final_output}")
        
        # === 2. last_agent ã®åˆ†æ ===
        print(f"\nğŸ¤– last_agent åˆ†æ:")
        print(f"   åå‰: {result.last_agent.name}")
        print(f"   ãƒ¢ãƒ‡ãƒ«: {result.last_agent.model}")
        print(f"   ãƒ„ãƒ¼ãƒ«æ•°: {len(result.last_agent.tools)}")
        print(f"   ãƒ„ãƒ¼ãƒ«: {[tool.name for tool in result.last_agent.tools]}")
        
        # === 3. new_items ã®è©³ç´°åˆ†æ ===
        print(f"\nğŸ“‹ new_items åˆ†æ:")
        print(f"   ç·ã‚¢ã‚¤ãƒ†ãƒ æ•°: {len(result.new_items)}")
        analyze_run_items(result.new_items)
        
        # === 4. Guardrailçµæœã®åˆ†æ ===
        print(f"\nğŸ›¡ï¸  Guardrail çµæœåˆ†æ:")
        if result.input_guardrail_results:
            print(f"   Input Guardrails: {len(result.input_guardrail_results)}ä»¶")
            for i, gr in enumerate(result.input_guardrail_results):
                print(f"     {i+1}. {gr.output_info}")
        
        if result.output_guardrail_results:
            print(f"   Output Guardrails: {len(result.output_guardrail_results)}ä»¶")
            for i, gr in enumerate(result.output_guardrail_results):
                print(f"     {i+1}. {gr.output_info}")
        
        # === 5. raw_responses ã®åˆ†æ ===
        print(f"\nğŸ”¤ raw_responses åˆ†æ:")
        print(f"   ç·ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ•°: {len(result.raw_responses)}")
        for i, response in enumerate(result.raw_responses):
            print(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹ {i+1}: {type(response).__name__}")
            if hasattr(response, 'model'):
                print(f"     ãƒ¢ãƒ‡ãƒ«: {response.model}")
            if hasattr(response, 'usage'):
                print(f"     ä½¿ç”¨é‡: {response.usage}")
        
        # === 6. input ã®ç¢ºèª ===
        print(f"\nğŸ“¥ å…ƒã®å…¥åŠ›:")
        print(f"   å…¥åŠ›: {result.input}")
        
        return result
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None


async def demonstrate_handoff_result_analysis(user_context: UserContext):
    """ãƒãƒ³ãƒ‰ã‚ªãƒ•ã‚’å«ã‚€Resultåˆ†æã®ãƒ‡ãƒ¢"""
    print("\n" + "="*80)
    print("ğŸ”„ 2. ãƒãƒ³ãƒ‰ã‚ªãƒ•ã‚’å«ã‚€Resultåˆ†æãƒ‡ãƒ¢")
    print("="*80)
    
    # å°‚é–€Agentç¾¤
    text_analyzer = Agent[UserContext](
        name="Text Analysis Specialist",
        instructions="ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã®å°‚é–€å®¶ã¨ã—ã¦è©³ç´°ãªåˆ†æã‚’æä¾›ã—ã¾ã™ã€‚",
        tools=[analyze_text],
        output_type=AnalysisResponse,
    )
    
    recommendation_agent = Agent[UserContext](
        name="Recommendation Specialist", 
        instructions="æ¨å¥¨äº‹é …ã®æä¾›å°‚é–€å®¶ã¨ã—ã¦å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚",
        tools=[generate_recommendation],
        output_type=AnalysisResponse,
    )
    
    # ãƒã‚¹ã‚¿ãƒ¼Agent
    master_agent = Agent[UserContext](
        name="Master Coordinator",
        instructions=(
            "å…¥åŠ›å†…å®¹ã‚’åˆ†æã—ã€é©åˆ‡ãªå°‚é–€Agentã«ãƒãƒ³ãƒ‰ã‚ªãƒ•ã—ã¾ã™ã€‚"
            "ãƒ†ã‚­ã‚¹ãƒˆåˆ†æãŒå¿…è¦ â†’ Text Analysis Specialist"
            "æ¨å¥¨äº‹é …ãŒå¿…è¦ â†’ Recommendation Specialist"
        ),
        model="gpt-4o-mini",
        handoffs=[
            handoff(text_analyzer, tool_description_override="è©³ç´°ãªãƒ†ã‚­ã‚¹ãƒˆåˆ†æãŒå¿…è¦ãªå ´åˆ"),
            handoff(recommendation_agent, tool_description_override="æ¨å¥¨äº‹é …ã®æä¾›ãŒå¿…è¦ãªå ´åˆ"),
        ]
    )
    
    test_inputs = [
        "ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†æã—ã¦ãã ã•ã„ï¼šã¨ã¦ã‚‚ç´ æ™´ã‚‰ã—ã„ä¸€æ—¥ã§ã—ãŸï¼",
        "æ–°ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å§‹ã‚ã‚‹ã®ã«ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ãã ã•ã„"
    ]
    
    for i, test_input in enumerate(test_inputs, 1):
        print(f"\nğŸ“ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i}: ã€Œ{test_input}ã€")
        print("-" * 60)
        
        try:
            result = await Runner.run(
                starting_agent=master_agent,
                input=test_input,
                context=user_context,
                max_turns=6
            )
            
            # === ãƒãƒ³ãƒ‰ã‚ªãƒ•ç‰¹åŒ–åˆ†æ ===
            print(f"ğŸ¯ ãƒãƒ³ãƒ‰ã‚ªãƒ•çµæœåˆ†æ:")
            print(f"   é–‹å§‹Agent: {master_agent.name}")
            print(f"   æœ€çµ‚Agent: {result.last_agent.name}")
            print(f"   ãƒãƒ³ãƒ‰ã‚ªãƒ•ç™ºç”Ÿ: {'Yes' if result.last_agent != master_agent else 'No'}")
            
            # === HandoffItem ã®è©³ç´°åˆ†æ ===
            handoff_items = [item for item in result.new_items if 'handoff' in item.type]
            if handoff_items:
                print(f"\nğŸ”„ ãƒãƒ³ãƒ‰ã‚ªãƒ•ã‚¢ã‚¤ãƒ†ãƒ åˆ†æ:")
                for j, item in enumerate(handoff_items):
                    print(f"   ãƒãƒ³ãƒ‰ã‚ªãƒ• {j+1}: {item.type}")
                    if hasattr(item, 'source_agent') and hasattr(item, 'target_agent'):
                        print(f"     {item.source_agent.name} â†’ {item.target_agent.name}")
            
            # === æœ€çµ‚å‡ºåŠ› ===
            print(f"\nğŸ’¬ æœ€çµ‚å‡ºåŠ›:")
            if hasattr(result.final_output, 'analysis'):
                print(f"   åˆ†æ: {result.final_output.analysis}")
                print(f"   æ¨å¥¨äº‹é …: {result.final_output.recommendations}")
                print(f"   ç·Šæ€¥åº¦: {result.final_output.urgency_level}")
            else:
                print(f"   å‡ºåŠ›: {result.final_output}")
                
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")


async def demonstrate_conversation_continuation(user_context: UserContext):
    """ä¼šè©±ç¶™ç¶šã®ãŸã‚ã®to_input_list()ãƒ‡ãƒ¢"""
    print("\n" + "="*80)
    print("ğŸ’¬ 3. ä¼šè©±ç¶™ç¶š (to_input_list) ãƒ‡ãƒ¢")
    print("="*80)
    
    conversation_agent = Agent[UserContext](
        name="Conversation Agent",
        instructions=(
            "å‰ã®ä¼šè©±å†…å®¹ã‚’è¦šãˆã¦ã€è‡ªç„¶ãªå¯¾è©±ã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚"
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸå›ç­”ã‚’æä¾›ã—ã¾ã™ã€‚"
        ),
        model="gpt-4o-mini",
        tools=[get_current_time],
    )
    
    # ä¼šè©±ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    conversation_turns = [
        "ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«ã¤ã„ã¦è©±ã—ãŸã„ã§ã™ã€‚",
        "OpenAI Agents SDKã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦ãã ã•ã„ã€‚",
        "å…ˆã»ã©èª¬æ˜ã—ã¦ã‚‚ã‚‰ã£ãŸSDKã®ä¸­ã§ä¸€ç•ªé‡è¦ãªæ©Ÿèƒ½ã¯ä½•ã§ã™ã‹ï¼Ÿ"
    ]
    
    current_input = None
    
    for turn_num, user_input in enumerate(conversation_turns, 1):
        print(f"\nğŸ—¨ï¸  ã‚¿ãƒ¼ãƒ³ {turn_num}")
        print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_input}")
        print("-" * 40)
        
        try:
            # æœ€åˆã®ã‚¿ãƒ¼ãƒ³ä»¥å¤–ã¯å‰ã®çµæœã‚’å¼•ãç¶™ã
            if current_input is None:
                run_input = user_input
                print("ğŸ“ åˆå›å…¥åŠ›ã‚’ä½¿ç”¨")
            else:
                # to_input_list()ã§å‰ã®ä¼šè©±å±¥æ­´ã‚’å«ã‚ã‚‹
                run_input = current_input + [{"role": "user", "content": user_input}]
                print(f"ğŸ“š ä¼šè©±å±¥æ­´ã‚’å«ã‚€å…¥åŠ›ã‚’ä½¿ç”¨ (ã‚¢ã‚¤ãƒ†ãƒ æ•°: {len(run_input)})")
            
            result = await Runner.run(
                starting_agent=conversation_agent,
                input=run_input,
                context=user_context,
                max_turns=4
            )
            
            print(f"ğŸ¤– Agent: {result.final_output}")
            
            # === to_input_list() ã®æ´»ç”¨ ===
            current_input = result.to_input_list()
            print(f"ğŸ“‹ æ¬¡å›ç”¨å…¥åŠ›ãƒªã‚¹ãƒˆæº–å‚™å®Œäº† (è¦ç´ æ•°: {len(current_input)})")
            
            # ä¼šè©±å±¥æ­´ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¨˜éŒ²
            user_context.conversation_history.append(f"User: {user_input}")
            user_context.conversation_history.append(f"Agent: {str(result.final_output)[:100]}...")
            
        except Exception as e:
            print(f"âŒ ã‚¿ãƒ¼ãƒ³ {turn_num} ã‚¨ãƒ©ãƒ¼: {str(e)}")
            break
    
    print(f"\nğŸ“š ä¼šè©±å±¥æ­´ã‚µãƒãƒªãƒ¼:")
    for i, entry in enumerate(user_context.conversation_history, 1):
        print(f"  {i}. {entry}")


async def demonstrate_streaming_result_analysis(user_context: UserContext):
    """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµæœã®åˆ†æãƒ‡ãƒ¢"""
    print("\n" + "="*80)
    print("ğŸ“¡ 4. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµæœåˆ†æãƒ‡ãƒ¢")
    print("="*80)
    
    streaming_agent = Agent[UserContext](
        name="Streaming Analyzer",
        instructions=(
            "è©³ç´°ã§æ®µéšçš„ãªåˆ†æã‚’æä¾›ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚"
            "åˆ†æéç¨‹ã‚’æ®µéšçš„ã«èª¬æ˜ã—ã€ãƒ„ãƒ¼ãƒ«ã‚’æ´»ç”¨ã—ã¦ç·åˆçš„ãªçµæœã‚’æä¾›ã—ã¾ã™ã€‚"
        ),
        model="gpt-4o-mini",
        tools=[analyze_text, generate_recommendation, get_current_time],
        output_type=TaskResponse,
    )
    
    test_input = "æœ€è¿‘ã€ãƒãƒ¼ãƒ ã§ã®å”åŠ›ãŒå•é¡Œã«ãªã£ã¦ã„ã¾ã™ã€‚åŠ¹æœçš„ãªè§£æ±ºç­–ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
    
    try:
        print(f"ğŸ“ å…¥åŠ›: ã€Œ{test_input}ã€")
        print("ğŸŒŠ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹...")
        print("-" * 60)
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œ
        streaming_result = Runner.run_streamed(
            starting_agent=streaming_agent,
            input=test_input,
            context=user_context,
            max_turns=5
        )
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†
        event_log = []
        text_chunks = []
        
        async for event in streaming_result.stream_events():
            event_info = {
                "type": event.type,
                "timestamp": datetime.datetime.now().isoformat()
            }
            
            if event.type == "raw_response_event":
                if hasattr(event.data, 'delta') and event.data.delta:
                    text_chunks.append(event.data.delta)
                    print(event.data.delta, end='', flush=True)
                    event_info["content"] = event.data.delta
                    
            elif event.type == "run_item_stream_event":
                item = event.item
                if item.type == "tool_call_item":
                    print(f"\nğŸ”§ [ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—] {item.tool_name}")
                    event_info["tool_name"] = item.tool_name
                elif item.type == "tool_call_output_item":
                    print(f"\nâœ… [ãƒ„ãƒ¼ãƒ«å®Œäº†] {item.output[:50]}...")
                    event_info["tool_output"] = item.output[:100]
                    
            event_log.append(event_info)
        
        print(f"\n\nğŸ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Œäº†")
        print("-" * 60)
        
        # === ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµæœã®è©³ç´°åˆ†æ ===
        final_result = streaming_result.final_result
        if final_result:
            print(f"ğŸ“Š ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµæœåˆ†æ:")
            print(f"   æœ€çµ‚å‡ºåŠ›ã‚¿ã‚¤ãƒ—: {type(final_result.final_output).__name__}")
            print(f"   å‡¦ç†ã•ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(event_log)}")
            print(f"   ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯æ•°: {len(text_chunks)}")
            print(f"   ç·æ–‡å­—æ•°: {sum(len(chunk) for chunk in text_chunks)}")
            
            # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®çµ±è¨ˆ
            event_types = {}
            for event in event_log:
                event_type = event['type']
                event_types[event_type] = event_types.get(event_type, 0) + 1
            
            print(f"\nğŸ“ˆ ã‚¤ãƒ™ãƒ³ãƒˆçµ±è¨ˆ:")
            for event_type, count in event_types.items():
                print(f"   {event_type}: {count}å›")
        
    except Exception as e:
        print(f"âŒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # API ã‚­ãƒ¼ã®ç¢ºèª
    if not check_api_key():
        sys.exit(1)
    
    try:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä½œæˆ
        user_context = UserContext(
            user_id="user_789",
            session_id="session_abc",
            conversation_history=[]
        )
        
        print("ğŸª OpenAI Agents SDK - Result å„è¦ç´  ãƒ‡ãƒ¢")
        print("="*80)
        print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {user_context.user_id}")
        print(f"ğŸ”— ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {user_context.session_id}")
        print("="*80)
        
        # 1. åŸºæœ¬çš„ãªResultåˆ†æ
        await demonstrate_basic_result_analysis(user_context)
        
        # 2. ãƒãƒ³ãƒ‰ã‚ªãƒ•ã‚’å«ã‚€Resultåˆ†æ
        await demonstrate_handoff_result_analysis(user_context)
        
        # 3. ä¼šè©±ç¶™ç¶šãƒ‡ãƒ¢
        await demonstrate_conversation_continuation(user_context)
        
        # 4. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµæœåˆ†æ
        await demonstrate_streaming_result_analysis(user_context)
        
        print(f"\nğŸ‰ å…¨Resultè¦ç´ ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†ï¼")
        print("="*80)
        print("ğŸ“š å­¦ç¿’å†…å®¹ã¾ã¨ã‚:")
        print("âœ… final_output - Agentå®Ÿè¡Œã®æœ€çµ‚çµæœ")
        print("âœ… last_agent - æœ€å¾Œã«å®Ÿè¡Œã•ã‚ŒãŸAgentæƒ…å ±")
        print("âœ… new_items - å®Ÿè¡Œä¸­ã«ç”Ÿæˆã•ã‚ŒãŸå„ç¨®ã‚¢ã‚¤ãƒ†ãƒ ")
        print("âœ… to_input_list() - ä¼šè©±ç¶™ç¶šã®ãŸã‚ã®å…¥åŠ›æº–å‚™")
        print("âœ… guardrail_results - å…¥åŠ›/å‡ºåŠ›æ¤œè¨¼çµæœ")
        print("âœ… raw_responses - LLMã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹")
        print("âœ… input - å…ƒã®å…¥åŠ›æƒ…å ±")
        print("âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµæœ - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†çµæœ")
        print("="*80)
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e).__name__}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())