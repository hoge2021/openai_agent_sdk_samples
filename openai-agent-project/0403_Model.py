#!/usr/bin/env python3
"""
OpenAI Agents SDK Model ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
ãƒ¢ãƒ‡ãƒ«ã®æ··åˆã¨ãƒãƒƒãƒãƒ³ã‚°ã€LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ä½¿ç”¨æ–¹æ³•ã‚’å®Ÿè£…
"""

import os
import asyncio
from typing import Dict, Any, Optional
from dotenv import load_dotenv
from pydantic import BaseModel

# OpenAI Agents SDKã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from agents import (
    Agent,
    Runner,
    ModelProvider,
    AsyncOpenAI,
    OpenAIResponsesModel,
    OpenAIChatCompletionsModel,
    set_default_openai_client,
    set_default_openai_api,
    set_tracing_disabled,
    set_tracing_export_api_key,
)


# ========== ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å®šç¾© ==========

class TaskResult(BaseModel):
    """ã‚¿ã‚¹ã‚¯å®Ÿè¡Œçµæœã®ãƒ¢ãƒ‡ãƒ«"""
    content: str
    model_used: str
    execution_time: float
    token_usage: str
    quality_rating: float


class ModelPerformanceReport(BaseModel):
    """ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ"""
    model_name: str
    avg_response_time: float
    total_tokens: int
    task_success_rate: float
    cost_estimate: float


# ========== ã‚«ã‚¹ã‚¿ãƒ ModelProviderã‚¯ãƒ©ã‚¹ ==========

class CustomModelProvider(ModelProvider):
    """ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®å®Ÿè£…ä¾‹"""
    
    def __init__(self):
        # å„ãƒ¢ãƒ‡ãƒ«åã«å¯¾å¿œã™ã‚‹ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ã‚’å®šç¾©
        self.models = {
            # é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ï¼ˆResponses APIä½¿ç”¨ï¼‰
            "gpt-4o": OpenAIResponsesModel(
                model="gpt-4o",
                openai_client=AsyncOpenAI()
            ),
            # æ¨™æº–ãƒ¢ãƒ‡ãƒ«ï¼ˆResponses APIä½¿ç”¨ï¼‰ 
            "gpt-4o-mini": OpenAIResponsesModel(
                model="gpt-4o-mini",
                openai_client=AsyncOpenAI()
            ),
            # è»½é‡ãƒ¢ãƒ‡ãƒ«ï¼ˆChatCompletions APIä½¿ç”¨ï¼‰
            "gpt-3.5-turbo": OpenAIChatCompletionsModel(
                model="gpt-3.5-turbo", 
                openai_client=AsyncOpenAI()
            ),
            # æ¨è«–ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ï¼ˆResponses APIå¯¾å¿œã®è¿‘ä¼¼ãƒ¢ãƒ‡ãƒ«ã«ç½®æ›ï¼‰
            "o3-mini": OpenAIResponsesModel(
                model="gpt-4o-mini",
                openai_client=AsyncOpenAI()
            ),
        }
    
    def get_model(self, model_name: str):
        """æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«åã«å¯¾å¿œã™ã‚‹ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ã‚’è¿”ã™"""
        if model_name not in self.models:
            raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«: {model_name}")
        return self.models[model_name]


# ========== ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®šç¾©ï¼ˆç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰ ==========

class ModelDemonstrationAgents:
    """æ§˜ã€…ãªãƒ¢ãƒ‡ãƒ«è¨­å®šã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self):
        # é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆç›´æ¥ãƒ¢ãƒ‡ãƒ«æŒ‡å®šï¼‰
        self.premium_agent = Agent(
            name="Premium Analysis Agent",
            instructions="""
            ã‚ãªãŸã¯é«˜åº¦ãªåˆ†æã‚’è¡Œã†å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
            è¤‡é›‘ãªå•é¡Œã«å¯¾ã—ã¦è©³ç´°ã§æ´å¯Ÿã«æº€ã¡ãŸåˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
            """,
            model=OpenAIResponsesModel(
                model="gpt-4o",
                openai_client=AsyncOpenAI()
            ),
            output_type=TaskResult,
        )
        
        # æ¨™æº–ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆãƒ¢ãƒ‡ãƒ«åæŒ‡å®šï¼‰
        self.standard_agent = Agent(
            name="Standard Processing Agent", 
            instructions="""
            ã‚ãªãŸã¯ä¸€èˆ¬çš„ãªã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
            åŠ¹ç‡çš„ã§å®Ÿç”¨çš„ãªå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
            """,
            model="gpt-4o-mini",
            output_type=TaskResult,
        )
        
        # è»½é‡ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆChatCompletions APIï¼‰
        self.lightweight_agent = Agent(
            name="Lightweight Agent",
            instructions="""
            ã‚ãªãŸã¯ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã‚’é«˜é€Ÿã§å‡¦ç†ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
            ç°¡æ½”ã§çš„ç¢ºãªå›ç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚
            """, 
            model=OpenAIChatCompletionsModel(
                model="gpt-3.5-turbo",
                openai_client=AsyncOpenAI()
            ),
            # ChatCompletionsç³»ã§ã¯æ§‹é€ åŒ–å‡ºåŠ›ã‚’ä½¿ã‚ãªã„
        )
        
        # æ¨è«–ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆResponses APIå¯¾å¿œãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›´ï¼‰
        self.reasoning_agent = Agent(
            name="Reasoning Specialist Agent",
            instructions="""
            ã‚ãªãŸã¯è«–ç†çš„æ¨è«–ã‚’å¾—æ„ã¨ã™ã‚‹å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
            è¤‡é›‘ãªè«–ç†å•é¡Œã‚„æ•°å­¦çš„å•é¡Œã‚’æ®µéšçš„ã«è§£æ±ºã—ã¦ãã ã•ã„ã€‚
            """,
            model=OpenAIResponsesModel(
                model="gpt-4o-mini",
                openai_client=AsyncOpenAI()
            ),
            output_type=TaskResult,
        )
        
        # ãƒˆãƒªã‚¢ãƒ¼ã‚¸ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆãƒ¢ãƒ‡ãƒ«é¸æŠã‚’è¡Œã†ï¼‰
        self.triage_agent = Agent(
            name="Model Selection Agent",
            instructions="""
            ã‚ãªãŸã¯ã‚¿ã‚¹ã‚¯ã®è¤‡é›‘ã•ã‚’åˆ¤å®šã—ã€é©åˆ‡ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é¸æŠã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
            ã‚¿ã‚¹ã‚¯ã®æ€§è³ªã«å¿œã˜ã¦æœ€é©ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒãƒ³ãƒ‰ã‚ªãƒ•ã—ã¦ãã ã•ã„ã€‚
            """,
            model="gpt-4o-mini",  # ãƒˆãƒªã‚¢ãƒ¼ã‚¸ã«ã¯ä¸­é–“æ€§èƒ½ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            handoffs=[
                # ãƒãƒ³ãƒ‰ã‚ªãƒ•å…ˆã¯å¾Œã§setãƒ¡ã‚½ãƒƒãƒ‰ã§è¨­å®š
            ]
        )
    
    def setup_handoffs(self):
        """ãƒãƒ³ãƒ‰ã‚ªãƒ•è¨­å®šï¼ˆå¾ªç’°å‚ç…§ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰"""
        self.triage_agent.handoffs = [
            self.premium_agent,
            self.standard_agent, 
            self.lightweight_agent,
            self.reasoning_agent,
        ]


# ========== ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ==========

class ModelUsageDemo:
    """ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    def __init__(self):
        self.agents = ModelDemonstrationAgents()
        self.agents.setup_handoffs()
        self.custom_provider = CustomModelProvider()
        self.performance_data = {}
    
    async def demo_method1_global_client(self):
        """
        æ–¹æ³•1: set_default_openai_client ã‚’ä½¿ç”¨ã—ãŸã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š
        """
        print("\nğŸŒ æ–¹æ³•1: ã‚°ãƒ­ãƒ¼ãƒãƒ«OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š")
        print("-" * 50)
        
        try:
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¨­å®š
            global_client = AsyncOpenAI(
                api_key=os.getenv("OPENAI_API_KEY"),
                # ãã®ä»–ã®ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã‚‚å¯èƒ½
                # base_url="https://api.openai.com/v1",
                # timeout=30.0,
            )
            set_default_openai_client(global_client)
            print("âœ… ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¨­å®šã—ã¾ã—ãŸ")
            
            # ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã‚’ä½¿ç”¨ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
            global_agent = Agent(
                name="Global Client Agent",
                instructions="ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚",
                model="gpt-4o-mini"
            )
            
            result = await Runner.run(
                global_agent, 
                "ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®šã§ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã§ã™ã€‚ç°¡æ½”ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚"
            )
            
            print(f"å¿œç­”: {result.final_output}")
            return {"method": "Global Client", "success": True, "result": result.final_output}
            
        except Exception as e:
            print(f"âŒ ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            return {"method": "Global Client", "success": False, "error": str(e)}
    
    async def demo_method2_runner_provider(self):
        """
        æ–¹æ³•2: ModelProvider ã‚’ Runner.run ãƒ¬ãƒ™ãƒ«ã§æŒ‡å®š
        """
        print("\nğŸ”§ æ–¹æ³•2: Runner.runãƒ¬ãƒ™ãƒ«ã§ã®ModelProvideræŒ‡å®š")
        print("-" * 50)
        
        try:
            # Runner.run ã« model_provider å¼•æ•°ã¯ç„¡ã„æƒ³å®šã®ãŸã‚ã€
            # Provider ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ã¦ä¸€æ™‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¦å®Ÿè¡Œ
            model_impl = self.custom_provider.get_model("gpt-4o-mini")
            temp_agent = Agent(
                name="Standard Processing Agent (Provider Override)",
                instructions="ModelProviderçµŒç”±ã§ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ã‚’å·®ã—æ›¿ãˆã¦å®Ÿè¡Œã—ã¾ã™ã€‚",
                model=model_impl,
                output_type=TaskResult,
            )

            result = await Runner.run(
                temp_agent,
                "ModelProviderã‚’ä½¿ç”¨ã—ãŸãƒ†ã‚¹ãƒˆå®Ÿè¡Œã§ã™ã€‚"
            )
            
            print(f"âœ… ModelProviderå®Ÿè¡ŒæˆåŠŸ")
            print(f"å¿œç­”: {result.final_output}")
            return {"method": "Runner ModelProvider", "success": True, "result": result.final_output}
            
        except Exception as e:
            print(f"âŒ ModelProviderå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return {"method": "Runner ModelProvider", "success": False, "error": str(e)}
    
    async def demo_method3_agent_specific(self):
        """
        æ–¹æ³•3: Agent.model ã‚’ä½¿ç”¨ã—ã¦ç‰¹å®šã®Agentã«ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®š
        """
        print("\nğŸ¯ æ–¹æ³•3: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå›ºæœ‰ã®ãƒ¢ãƒ‡ãƒ«æŒ‡å®š")
        print("-" * 50)
        
        test_cases = [
            ("Premium Agent (GPT-4o + Responses API)", self.agents.premium_agent),
            ("Standard Agent (GPT-4o-mini)", self.agents.standard_agent),
            ("Lightweight Agent (GPT-3.5 + ChatCompletions API)", self.agents.lightweight_agent),
            ("Reasoning Agent (gpt-4o-mini)", self.agents.reasoning_agent),
        ]
        
        results = []
        
        for name, agent in test_cases:
            try:
                print(f"\n  ğŸ¤– {name} ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
                
                import time
                start_time = time.time()
                
                result = await Runner.run(
                    agent,
                    f"{agent.name}ã¨ã—ã¦ã€ã‚ãªãŸã®å°‚é–€åˆ†é‡ã«ã¤ã„ã¦30æ–‡å­—ç¨‹åº¦ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
                )
                
                execution_time = time.time() - start_time
                
                print(f"     âœ… å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
                print(f"     å¿œç­”: {result.final_output}")
                
                results.append({
                    "agent_name": name,
                    "success": True,
                    "execution_time": execution_time,
                    "result": result.final_output
                })
                
            except Exception as e:
                print(f"     âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                results.append({
                    "agent_name": name,
                    "success": False,
                    "error": str(e)
                })
        
        return {"method": "Agent-specific Models", "results": results}
    
    async def demo_model_mixing(self):
        """
        ãƒ¢ãƒ‡ãƒ«ã®æ··åˆã¨ãƒãƒƒãƒãƒ³ã‚°: è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã§ã®å‹•çš„ãƒ¢ãƒ‡ãƒ«é¸æŠ
        """
        print("\nğŸ­ ãƒ¢ãƒ‡ãƒ«æ··åˆãƒ»ãƒãƒƒãƒãƒ³ã‚°ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        print("-" * 50)
        
        complex_tasks = [
            {
                "task": "äººå·¥çŸ¥èƒ½ã®å€«ç†çš„èª²é¡Œã«ã¤ã„ã¦è«–æ–‡ã®æ¦‚è¦ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚",
                "expected_agent": "Premium Analysis Agent"
            },
            {
                "task": "ä»Šæ—¥ã®å¤©æ°—ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚", 
                "expected_agent": "Lightweight Agent"
            },
            {
                "task": "ãƒ•ã‚£ãƒœãƒŠãƒƒãƒæ•°åˆ—ã®10ç•ªç›®ã®å€¤ã‚’è¨ˆç®—ã—ã€è¨ˆç®—éç¨‹ã‚‚ç¤ºã—ã¦ãã ã•ã„ã€‚",
                "expected_agent": "Reasoning Specialist Agent"
            }
        ]
        
        results = []
        
        for task_info in complex_tasks:
            try:
                print(f"\n  ğŸ“ ã‚¿ã‚¹ã‚¯: {task_info['task']}")
                
                # ãƒˆãƒªã‚¢ãƒ¼ã‚¸ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒé©åˆ‡ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é¸æŠ
                result = await Runner.run(
                    self.agents.triage_agent,
                    task_info["task"]
                )
                
                print(f"     âœ… å‡¦ç†å®Œäº†")
                print(f"     å¿œç­”: {str(result.final_output)[:100]}...")
                
                results.append({
                    "task": task_info["task"],
                    "success": True,
                    "result": result.final_output
                })
                
            except Exception as e:
                print(f"     âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                results.append({
                    "task": task_info["task"], 
                    "success": False,
                    "error": str(e)
                })
        
        return {"method": "Model Mixing", "results": results}
    
    async def demo_api_compatibility(self):
        """
        ç•°ãªã‚‹APIã‚¿ã‚¤ãƒ—ã®äº’æ›æ€§ãƒ†ã‚¹ãƒˆ
        """
        print("\nğŸ”„ APIäº’æ›æ€§ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        print("-" * 50)
        
        try:
            # Responses API vs ChatCompletions API ã®æ¯”è¼ƒ
            test_query = "APIã®é•ã„ã«ã¤ã„ã¦50æ–‡å­—ç¨‹åº¦ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
            
            # Responses API ã‚’ä½¿ç”¨
            responses_agent = Agent(
                name="Responses API Test",
                instructions="Responses APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚",
                model=OpenAIResponsesModel(
                    model="gpt-4o-mini",
                    openai_client=AsyncOpenAI()
                )
            )
            
            responses_result = await Runner.run(responses_agent, test_query)
            print(f"âœ… Responses APIçµæœ: {responses_result.final_output}")
            
            # ChatCompletions API ã‚’ä½¿ç”¨
            chat_agent = Agent(
                name="ChatCompletions API Test",
                instructions="ChatCompletions APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚",
                model=OpenAIChatCompletionsModel(
                    model="gpt-4o-mini",
                    openai_client=AsyncOpenAI()
                )
            )
            
            chat_result = await Runner.run(chat_agent, test_query)
            print(f"âœ… ChatCompletions APIçµæœ: {chat_result.final_output}")
            
            return {
                "method": "API Compatibility",
                "responses_api": responses_result.final_output,
                "chatcompletions_api": chat_result.final_output,
                "success": True
            }
            
        except Exception as e:
            print(f"âŒ APIäº’æ›æ€§ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"method": "API Compatibility", "success": False, "error": str(e)}
    
    async def handle_common_provider_issues(self):
        """
        ä»–ã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ä½¿ç”¨æ™‚ã®ä¸€èˆ¬çš„ãªå•é¡Œã¸ã®å¯¾å‡¦
        """
        print("\nâš ï¸  LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å•é¡Œã¸ã®å¯¾å‡¦ä¾‹")
        print("-" * 50)
        
        solutions = []
        
        # å•é¡Œ1: ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼401
        print("  ğŸ“‹ å•é¡Œ1: ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼401ã¸ã®å¯¾å‡¦")
        try:
            # è§£æ±ºç­–1: ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’ç„¡åŠ¹åŒ–
            set_tracing_disabled(True)
            print("     âœ… è§£æ±ºç­–1: ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã—ãŸ")
            solutions.append("ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ç„¡åŠ¹åŒ–")
            
            # è§£æ±ºç­–2: ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ç”¨APIã‚­ãƒ¼ã‚’è¨­å®šï¼ˆãƒ‡ãƒ¢ã®ã¿ï¼‰
            if os.getenv("OPENAI_API_KEY"):
                # å®Ÿéš›ã®æœ¬ç•ªç’°å¢ƒã§ã¯å°‚ç”¨ã®APIã‚­ãƒ¼ã‚’ä½¿ç”¨
                set_tracing_export_api_key(os.getenv("OPENAI_API_KEY"))
                print("     âœ… è§£æ±ºç­–2: ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ç”¨APIã‚­ãƒ¼ã‚’è¨­å®šï¼ˆãƒ‡ãƒ¢ï¼‰")
                solutions.append("ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ç”¨APIã‚­ãƒ¼è¨­å®š")
                
        except Exception as e:
            print(f"     âš ï¸ ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°è¨­å®šè­¦å‘Š: {e}")
        
        # å•é¡Œ2: Responses APIã‚µãƒãƒ¼ãƒˆä¸è¶³
        print("\n  ğŸ“‹ å•é¡Œ2: Responses APIã‚µãƒãƒ¼ãƒˆä¸è¶³ã¸ã®å¯¾å‡¦")
        try:
            # è§£æ±ºç­–: ChatCompletions APIã‚’ä½¿ç”¨
            set_default_openai_api("chat_completions")
            print("     âœ… ChatCompletions APIã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«è¨­å®šã—ã¾ã—ãŸ")
            solutions.append("ChatCompletions APIä½¿ç”¨")
            
        except Exception as e:
            print(f"     âš ï¸ APIè¨­å®šè­¦å‘Š: {e}")
        
        # å•é¡Œ3: æ§‹é€ åŒ–å‡ºåŠ›ã‚µãƒãƒ¼ãƒˆä¸è¶³
        print("\n  ğŸ“‹ å•é¡Œ3: æ§‹é€ åŒ–å‡ºåŠ›ã‚µãƒãƒ¼ãƒˆå¯¾å¿œ")
        try:
            # OpenAIä»¥å¤–ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ã¯æ§‹é€ åŒ–å‡ºåŠ›ã«åˆ¶é™ãŒã‚ã‚‹å ´åˆã®å¯¾å‡¦
            simple_agent = Agent(
                name="Simple Output Agent",
                instructions="""
                æ§‹é€ åŒ–å‡ºåŠ›ã‚’ã‚µãƒãƒ¼ãƒˆã—ãªã„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å‘ã‘ã«ã€
                ã‚·ãƒ³ãƒ—ãƒ«ãªæ–‡å­—åˆ—å½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚
                """,
                # output_typeã‚’æŒ‡å®šã—ãªã„ï¼ˆãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ï¼‰
            )
            
            result = await Runner.run(
                simple_agent,
                "æ§‹é€ åŒ–å‡ºåŠ›åˆ¶é™ã®å›é¿ãƒ†ã‚¹ãƒˆã§ã™ã€‚"
            )
            print(f"     âœ… éæ§‹é€ åŒ–å‡ºåŠ›ãƒ†ã‚¹ãƒˆæˆåŠŸ: {result.final_output}")
            solutions.append("éæ§‹é€ åŒ–å‡ºåŠ›ä½¿ç”¨")
            
        except Exception as e:
            print(f"     âŒ æ§‹é€ åŒ–å‡ºåŠ›ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        
        return {
            "method": "Provider Issues Handling",
            "solutions_applied": solutions,
            "success": len(solutions) > 0
        }


# ========== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ==========

def load_environment():
    """ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ã€å¿…è¦ãªãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†"""
    load_dotenv()
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError(
            "OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
            ".envãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã®å½¢å¼ã§è¨­å®šã—ã¦ãã ã•ã„ï¼š\n"
            "OPENAI_API_KEY=your_api_key_here"
        )
    
    print("âœ… ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ")
    return api_key


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸš€ OpenAI Agents SDK Model ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ã‚°ãƒ©ãƒ é–‹å§‹")
    print("=" * 80)
    
    try:
        # ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ã¨ãƒã‚§ãƒƒã‚¯
        load_environment()
        
        # ModelUsageDemoã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        demo = ModelUsageDemo()
        
        # å„ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é †æ¬¡å®Ÿè¡Œ
        demonstrations = [
            ("ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š", demo.demo_method1_global_client),
            ("Runner ModelProvider", demo.demo_method2_runner_provider),
            ("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå›ºæœ‰ãƒ¢ãƒ‡ãƒ«", demo.demo_method3_agent_specific),
            ("ãƒ¢ãƒ‡ãƒ«æ··åˆãƒ»ãƒãƒƒãƒãƒ³ã‚°", demo.demo_model_mixing),
            ("APIäº’æ›æ€§ãƒ†ã‚¹ãƒˆ", demo.demo_api_compatibility),
            ("ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å•é¡Œå¯¾å‡¦", demo.handle_common_provider_issues),
        ]
        
        results_summary = []
        
        for demo_name, demo_func in demonstrations:
            print(f"\n{'='*80}")
            print(f"ğŸ¯ {demo_name} ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
            print("=" * 80)
            
            try:
                result = await demo_func()
                results_summary.append(result)
                print(f"âœ… {demo_name} å®Œäº†")
                
            except Exception as e:
                print(f"âŒ {demo_name} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                results_summary.append({
                    "method": demo_name,
                    "success": False,
                    "error": str(e)
                })
        
        # çµæœã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º
        print(f"\n{'='*80}")
        print("ğŸ“Š å®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 80)
        
        successful_demos = 0
        for result in results_summary:
            if result.get("success", False):
                successful_demos += 1
                print(f"âœ… {result.get('method', 'Unknown')}: æˆåŠŸ")
            else:
                print(f"âŒ {result.get('method', 'Unknown')}: å¤±æ•— - {result.get('error', 'ä¸æ˜')}")
        
        print(f"\nğŸ‰ ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: {successful_demos}/{len(demonstrations)} æˆåŠŸ")
        
        print(f"\nğŸ’¡ ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹:")
        print("â€¢ è»½é‡ã‚¿ã‚¹ã‚¯ã«ã¯é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨")
        print("â€¢ è¤‡é›‘ãªåˆ†æã«ã¯é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨") 
        print("â€¢ è«–ç†æ¨è«–ã«ã¯o1ã‚·ãƒªãƒ¼ã‚ºã‚’ä½¿ç”¨")
        print("â€¢ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å›ºæœ‰ã®åˆ¶é™ã«æ³¨æ„ã—ã¦å®Ÿè£…")
        
    except ValueError as e:
        print(f"âŒ ç’°å¢ƒè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        return 1
        
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print(f"ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    exit(exit_code)