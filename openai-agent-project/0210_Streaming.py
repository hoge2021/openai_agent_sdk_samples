#!/usr/bin/env python3
"""
OpenAI Agents SDK - Streamingå„è¦ç´  ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
"""

import asyncio
import os
import sys
import datetime
import time
from dataclasses import dataclass
from typing import Any, List, Dict

# OpenAI Agents SDK ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from pydantic import BaseModel
    from openai.types.responses import ResponseTextDeltaEvent
    from agents import (
        Agent,
        Runner,
        AgentOutputSchema,
        RunContextWrapper,
        function_tool,
        handoff,
        ItemHelpers
    )
    from agents.stream_events import (
        StreamEvent,
        RawResponsesStreamEvent,
        RunItemStreamEvent,
        AgentUpdatedStreamEvent
    )
except ImportError:
    print("âŒ ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install openai-agents pydantic")
    sys.exit(1)


# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å®šç¾©
@dataclass
class UserContext:
    user_id: str
    session_id: str
    preferences: Dict[str, Any]


# å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
class StreamingResponse(BaseModel):
    content: str
    status: str
    processing_time: float
    metadata: Dict[str, Any]


# ãƒ„ãƒ¼ãƒ«é–¢æ•°ç¾¤
@function_tool
def get_current_time() -> str:
    """ç¾åœ¨ã®æ—¥æ™‚ã‚’å–å¾—ã™ã‚‹"""
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")


@function_tool
def generate_random_number(min_val: int = 1, max_val: int = 100) -> str:
    """æŒ‡å®šç¯„å›²ã®ãƒ©ãƒ³ãƒ€ãƒ æ•°ã‚’ç”Ÿæˆã™ã‚‹"""
    import random
    number = random.randint(min_val, max_val)
    return f"ç”Ÿæˆã•ã‚ŒãŸãƒ©ãƒ³ãƒ€ãƒ æ•°: {number}"


@function_tool
def simulate_data_processing(duration: int = 3) -> str:
    """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ï¼ˆæ™‚é–“ã®ã‹ã‹ã‚‹å‡¦ç†ï¼‰"""
    print(f"   ğŸ”„ ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–‹å§‹... ({duration}ç§’)")
    time.sleep(duration)  # å‡¦ç†æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    
    results = [
        "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€é©åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ",
        "1000ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‡¦ç†ã—ã¾ã—ãŸ",
        "çµ±è¨ˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ",
        "æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸ"
    ]
    
    import random
    result = random.choice(results)
    print(f"   âœ… ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†: {result}")
    return result


@function_tool
def search_knowledge_base(query: str) -> str:
    """çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’æ¤œç´¢ã™ã‚‹ï¼ˆæ¨¡æ“¬ï¼‰"""
    knowledge_base = {
        "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°": "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¯è«–ç†çš„æ€è€ƒã¨ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚’çµ„ã¿åˆã‚ã›ãŸã‚¹ã‚­ãƒ«ã§ã™",
        "AI": "äººå·¥çŸ¥èƒ½ã¯æ©Ÿæ¢°å­¦ç¿’ã€è‡ªç„¶è¨€èªå‡¦ç†ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ãªã©ã®æŠ€è¡“ã‚’å«ã¿ã¾ã™",
        "python": "Pythonã¯èª­ã¿ã‚„ã™ãã€å¤šç›®çš„ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™",
        "æ©Ÿæ¢°å­¦ç¿’": "æ©Ÿæ¢°å­¦ç¿’ã¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã™ã‚‹æŠ€è¡“ã§ã™"
    }
    
    # ç°¡å˜ãªæ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯
    for key, value in knowledge_base.items():
        if key.lower() in query.lower():
            return f"æ¤œç´¢çµæœ: {value}"
    
    return f"'{query}'ã«é–¢ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸãŒã€ä¸€èˆ¬çš„ãªæŠ€è¡“ã‚µãƒãƒ¼ãƒˆã‚’æä¾›ã§ãã¾ã™ã€‚"


class StreamingEventAnalyzer:
    """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¤ãƒ™ãƒ³ãƒˆã®åˆ†æãƒ»çµ±è¨ˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.event_stats = {}
        self.raw_text_chunks = []
        self.tool_executions = []
        self.agent_changes = []
        self.start_time = None
        self.total_events = 0
        
    def reset(self):
        """çµ±è¨ˆã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.__init__()
        
    def _safe_tool_name(self, item: Any) -> str:
        raw = getattr(item, 'raw_item', None)
        name = getattr(raw, 'name', None)
        if name:
            return name
        item_type = getattr(raw, 'type', None)
        return item_type if isinstance(item_type, str) else 'Unknown'

    def record_event(self, event: StreamEvent):
        """ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¨˜éŒ²"""
        if self.start_time is None:
            self.start_time = time.time()
            
        self.total_events += 1
        event_type = event.type
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
        self.event_stats[event_type] = self.event_stats.get(event_type, 0) + 1
        
        # ã‚¤ãƒ™ãƒ³ãƒˆè©³ç´°ã®è¨˜éŒ²
        if event_type == "raw_response_event":
            if hasattr(event.data, 'delta') and event.data.delta:
                self.raw_text_chunks.append(event.data.delta)
                
        elif event_type == "run_item_stream_event":
            item = event.item
            if item.type == "tool_call_item":
                self.tool_executions.append({
                    "tool_name": self._safe_tool_name(item),
                    "timestamp": time.time()
                })
                
        elif event_type == "agent_updated_stream_event":
            self.agent_changes.append({
                "new_agent": event.new_agent.name,
                "timestamp": time.time()
            })
    
    def get_summary(self) -> Dict[str, Any]:
        """åˆ†æçµæœã®ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
        total_time = time.time() - self.start_time if self.start_time else 0
        total_text_length = sum(len(chunk) for chunk in self.raw_text_chunks)
        
        return {
            "execution_time": total_time,
            "total_events": self.total_events,
            "event_breakdown": self.event_stats,
            "text_generation": {
                "chunks": len(self.raw_text_chunks),
                "total_characters": total_text_length,
                "avg_chunk_size": total_text_length / max(1, len(self.raw_text_chunks))
            },
            "tool_usage": {
                "executions": len(self.tool_executions),
                "tools_used": list(set(t["tool_name"] for t in self.tool_executions))
            },
            "agent_changes": len(self.agent_changes)
        }


def check_api_key():
    """OpenAI API ã‚­ãƒ¼ã®å­˜åœ¨ç¢ºèª"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("ä»¥ä¸‹ã®æ–¹æ³•ã§è¨­å®šã—ã¦ãã ã•ã„:")
        print("  Linux/Mac: export OPENAI_API_KEY='your-api-key-here'")
        print("  Windows: set OPENAI_API_KEY=your-api-key-here")
        return False
    
    if not api_key.startswith("sk-"):
        print("âš ï¸  è­¦å‘Š: API ã‚­ãƒ¼ã®å½¢å¼ãŒæ­£ã—ããªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        print("OpenAI API ã‚­ãƒ¼ã¯é€šå¸¸ 'sk-' ã§å§‹ã¾ã‚Šã¾ã™ã€‚")
    
    print("âœ… API ã‚­ãƒ¼ãŒæ­£å¸¸ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã™")
    return True


async def demonstrate_basic_streaming(user_context: UserContext):
    """åŸºæœ¬çš„ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã®ãƒ‡ãƒ¢"""
    print("\n" + "="*80)
    print("ğŸ“¡ 1. åŸºæœ¬çš„ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢")
    print("="*80)
    
    # åŸºæœ¬ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°Agent
    streaming_agent = Agent[UserContext](
        name="Basic Streaming Agent",
        instructions=(
            "ã‚ãªãŸã¯è¦ªåˆ‡ã§è©³ç´°ãªèª¬æ˜ã‚’ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
            "è³ªå•ã«å¯¾ã—ã¦ã€æ®µéšçš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„å›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
            "å¿…è¦ã«å¿œã˜ã¦ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚"
        ),
        model="gpt-4o-mini",
        tools=[get_current_time, generate_random_number],
        output_type=AgentOutputSchema(StreamingResponse, strict_json_schema=False),
    )
    
    test_input = "ç¾åœ¨ã®æ™‚åˆ»ã‚’æ•™ãˆã¦ã€ãã—ã¦1ã‹ã‚‰10ã®é–“ã§ãƒ©ãƒ³ãƒ€ãƒ ãªæ•°å­—ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    
    try:
        print(f"ğŸ“ å…¥åŠ›: ã€Œ{test_input}ã€")
        print("ğŸŒŠ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹...")
        print("-" * 80)
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œ
        streaming_result = Runner.run_streamed(
            starting_agent=streaming_agent,
            input=test_input,
            context=user_context,
            max_turns=5
        )
        
        # ã‚¤ãƒ™ãƒ³ãƒˆåˆ†æå™¨
        analyzer = StreamingEventAnalyzer()
        
        print("ğŸ’­ ç”Ÿæˆä¸­: ", end="", flush=True)
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†
        async for event in streaming_result.stream_events():
            analyzer.record_event(event)
            
            # === Raw Response Events ===
            if event.type == "raw_response_event":
                # ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
                if isinstance(event.data, ResponseTextDeltaEvent):
                    print(event.data.delta, end="", flush=True)
                    
            # === Run Item Stream Events ===
            elif event.type == "run_item_stream_event":
                item = event.item
                
                if item.type == "tool_call_item":
                    tool_name = StreamingEventAnalyzer()._safe_tool_name(item)
                    print(f"\nğŸ”§ [ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—] {tool_name}")
                    if hasattr(item, 'raw_item') and hasattr(item.raw_item, 'function'):
                        args = getattr(item.raw_item.function, 'arguments', 'N/A')
                        print(f"   å¼•æ•°: {args}")
                        
                elif item.type == "tool_call_output_item":
                    print(f"ğŸ”¨ [ãƒ„ãƒ¼ãƒ«å®Œäº†] {item.output}")
                    
                elif item.type == "message_output_item":
                    print(f"\nğŸ’¬ [ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å®Œäº†]")
                    # ItemHelpersã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                    message_text = ItemHelpers.text_message_output(item)
                    if message_text:
                        print(f"   å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {message_text[:100]}...")
                        
            # === Agent Updated Events ===
            elif event.type == "agent_updated_stream_event":
                print(f"\nğŸ”„ [Agentå¤‰æ›´] {event.new_agent.name}")
        
        print(f"\nğŸ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Œäº†")
        print("-" * 80)
        
        # åˆ†æçµæœã®è¡¨ç¤º
        summary = analyzer.get_summary()
        print(f"ğŸ“Š ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ†æçµæœ:")
        print(f"   å®Ÿè¡Œæ™‚é–“: {summary['execution_time']:.2f}ç§’")
        print(f"   ç·ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {summary['total_events']}")
        print(f"   ã‚¤ãƒ™ãƒ³ãƒˆå†…è¨³: {summary['event_breakdown']}")
        print(f"   ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ: {summary['text_generation']}")
        print(f"   ãƒ„ãƒ¼ãƒ«ä½¿ç”¨: {summary['tool_usage']}")
        
        # æœ€çµ‚çµæœã®å–å¾—
        final_result = streaming_result.final_output
        if final_result:
            print(f"\nğŸ¯ æœ€çµ‚çµæœ:")
            if hasattr(final_result, 'content'):
                print(f"   å†…å®¹: {final_result.content}")
                if hasattr(final_result, 'status'):
                    print(f"   ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {final_result.status}")
            else:
                print(f"   å‡ºåŠ›: {final_result}")
                
    except Exception as e:
        print(f"âŒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")


async def demonstrate_advanced_streaming_with_tools(user_context: UserContext):
    """ãƒ„ãƒ¼ãƒ«ã‚’å¤šç”¨ã™ã‚‹é«˜åº¦ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢"""
    print("\n" + "="*80)
    print("ğŸ”§ 2. é«˜åº¦ãªãƒ„ãƒ¼ãƒ«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢")
    print("="*80)
    
    # ãƒ„ãƒ¼ãƒ«é›†ç´„å‹Agent
    tool_heavy_agent = Agent[UserContext](
        name="Tool-Heavy Processing Agent",
        instructions=(
            "ã‚ãªãŸã¯è¤‡æ•°ã®ãƒ„ãƒ¼ãƒ«ã‚’åŠ¹ç‡çš„ã«ä½¿ç”¨ã—ã¦ã€"
            "è¤‡é›‘ãªå‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã§ã™ã€‚"
            "å‡¦ç†ã®é€²è¡ŒçŠ¶æ³ã‚’è©³ã—ãèª¬æ˜ã—ã€å„ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œçµæœã‚’çµ±åˆã—ã¦ãã ã•ã„ã€‚"
        ),
        model="gpt-4o-mini",
        tools=[
            get_current_time,
            simulate_data_processing,
            search_knowledge_base,
            generate_random_number
        ],
        output_type=AgentOutputSchema(StreamingResponse, strict_json_schema=False),
    )
    
    test_input = "AIã«ã¤ã„ã¦èª¿ã¹ã¦ã€ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’å®Ÿè¡Œã—ã€ç¾åœ¨æ™‚åˆ»ã¨å…±ã«ç·åˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
    
    try:
        print(f"ğŸ“ è¤‡é›‘ãªå‡¦ç†è¦æ±‚: ã€Œ{test_input}ã€")
        print("ğŸ”„ é«˜åº¦ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†é–‹å§‹...")
        print("-" * 80)
        
        streaming_result = Runner.run_streamed(
            starting_agent=tool_heavy_agent,
            input=test_input,
            context=user_context,
            max_turns=8
        )
        
        # è©³ç´°ãªåˆ†æå™¨
        analyzer = StreamingEventAnalyzer()
        tool_start_times = {}
        
        print("ğŸ¬ å‡¦ç†å®Ÿæ³ä¸­ç¶™:")
        print("-" * 40)
        
        async for event in streaming_result.stream_events():
            analyzer.record_event(event)
            
            if event.type == "raw_response_event":
                # ç”Ÿãƒ†ã‚­ã‚¹ãƒˆã¯æ§ãˆã‚ã«è¡¨ç¤º
                if isinstance(event.data, ResponseTextDeltaEvent) and event.data.delta:
                    if len(event.data.delta.strip()) > 0:  # ç©ºç™½ã§ãªã„å ´åˆã®ã¿
                        print(".", end="", flush=True)
                        
            elif event.type == "run_item_stream_event":
                item = event.item
                
                if item.type == "tool_call_item":
                    tool_name = StreamingEventAnalyzer()._safe_tool_name(item)
                    tool_start_times[tool_name] = time.time()
                    print(f"\nğŸš€ [{datetime.datetime.now().strftime('%H:%M:%S')}] {tool_name} å®Ÿè¡Œé–‹å§‹")
                    
                elif item.type == "tool_call_output_item":
                    tool_name = getattr(getattr(item, 'raw_item', None), 'name', None) or getattr(item, 'tool_name', 'Unknown')
                    duration = time.time() - tool_start_times.get(tool_name, time.time())
                    
                    print(f"âœ… [{datetime.datetime.now().strftime('%H:%M:%S')}] {tool_name} å®Œäº† ({duration:.1f}ç§’)")
                    print(f"   çµæœ: {item.output[:80]}{'...' if len(item.output) > 80 else ''}")
                    
                elif item.type == "message_output_item":
                    print(f"\nğŸ“ [{datetime.datetime.now().strftime('%H:%M:%S')}] ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆå®Œäº†")
                    
            elif event.type == "agent_updated_stream_event":
                print(f"\nğŸ”„ [{datetime.datetime.now().strftime('%H:%M:%S')}] Agentå¤‰æ›´: {event.new_agent.name}")
        
        print(f"\nğŸ‰ è¤‡é›‘å‡¦ç†å®Œäº†ï¼")
        print("-" * 80)
        
        # è©³ç´°åˆ†æçµæœ
        summary = analyzer.get_summary()
        print(f"ğŸ“ˆ è©³ç´°åˆ†æçµæœ:")
        print(f"   ç·å‡¦ç†æ™‚é–“: {summary['execution_time']:.2f}ç§’")
        print(f"   ä½¿ç”¨ãƒ„ãƒ¼ãƒ«: {', '.join(summary['tool_usage']['tools_used'])}")
        print(f"   ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå›æ•°: {summary['tool_usage']['executions']}")
        print(f"   å¹³å‡å®Ÿè¡Œé–“éš”: {summary['execution_time']/max(1, summary['total_events']):.2f}ç§’/ã‚¤ãƒ™ãƒ³ãƒˆ")
        
        # æœ€çµ‚çµæœ
        final_result = streaming_result.final_output
        if final_result and hasattr(final_result, 'content'):
            print(f"\nğŸ“‹ æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ:")
            print(f"   {final_result.content}")
            
    except Exception as e:
        print(f"âŒ é«˜åº¦ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")


async def demonstrate_handoff_streaming(user_context: UserContext):
    """ãƒãƒ³ãƒ‰ã‚ªãƒ•ã‚’å«ã‚€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢"""
    print("\n" + "="*80)
    print("ğŸ”„ 3. ãƒãƒ³ãƒ‰ã‚ªãƒ•ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢")
    print("="*80)
    
    # å°‚é–€Agentç¾¤
    time_specialist = Agent[UserContext](
        name="Time Management Specialist",
        instructions="æ™‚é–“ç®¡ç†ã¨æ™‚åˆ»ã«é–¢ã™ã‚‹å°‚é–€çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚",
        tools=[get_current_time],
        output_type=AgentOutputSchema(StreamingResponse, strict_json_schema=False),
    )
    
    data_specialist = Agent[UserContext](
        name="Data Processing Specialist", 
        instructions="ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨åˆ†æã®å°‚é–€å®¶ã¨ã—ã¦è©³ç´°ãªå‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚",
        tools=[simulate_data_processing, search_knowledge_base],
        output_type=AgentOutputSchema(StreamingResponse, strict_json_schema=False),
    )
    
    # ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼Agent
    coordinator_agent = Agent[UserContext](
        name="Task Coordinator",
        instructions=(
            "ã‚¿ã‚¹ã‚¯ã®å†…å®¹ã‚’åˆ†æã—ã€é©åˆ‡ãªå°‚é–€Agentã«ãƒãƒ³ãƒ‰ã‚ªãƒ•ã—ã¾ã™ã€‚"
            "æ™‚é–“é–¢é€£ â†’ Time Management Specialist"
            "ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢é€£ â†’ Data Processing Specialist"
        ),
        model="gpt-4o-mini",
        handoffs=[
            handoff(time_specialist, tool_description_override="æ™‚é–“ç®¡ç†ã‚„æ™‚åˆ»é–¢é€£ã®å‡¦ç†ãŒå¿…è¦"),
            handoff(data_specialist, tool_description_override="ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚„åˆ†æãŒå¿…è¦"),
        ]
    )
    
    test_cases = [
        "ç¾åœ¨ã®æ™‚åˆ»ã‚’ç¢ºèªã—ã¦ã€åŠ¹ç‡çš„ãªæ™‚é–“ç®¡ç†ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ãã ã•ã„",
        "å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¦ã€çµæœã®çµ±è¨ˆåˆ†æã‚’ãŠé¡˜ã„ã—ã¾ã™",
        "ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã®èª¿å­ã¯ã©ã†ã§ã™ã‹ï¼Ÿ"  # ãƒãƒ³ãƒ‰ã‚ªãƒ•ã•ã‚Œãªã„å ´åˆ
    ]
    
    for i, test_input in enumerate(test_cases, 1):
        print(f"\nğŸ“‹ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i}: ã€Œ{test_input}ã€")
        print("-" * 60)
        
        try:
            streaming_result = Runner.run_streamed(
                starting_agent=coordinator_agent,
                input=test_input,
                context=user_context,
                max_turns=6
            )
            
            analyzer = StreamingEventAnalyzer()
            current_agent = coordinator_agent.name
            handoff_count = 0
            
            print(f"ğŸ¯ é–‹å§‹Agent: {current_agent}")
            print("ğŸŒŠ å®Ÿè¡Œãƒ•ãƒ­ãƒ¼:")
            
            async for event in streaming_result.stream_events():
                analyzer.record_event(event)
                
                if event.type == "raw_response_event":
                    # ãƒãƒ³ãƒ‰ã‚ªãƒ•ä¸­ã¯ç”Ÿãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã‚’æ§ãˆã‚‹
                    if isinstance(event.data, ResponseTextDeltaEvent) and event.data.delta:
                        print("â€¢", end="", flush=True)
                        
                elif event.type == "agent_updated_stream_event":
                    handoff_count += 1
                    old_agent = current_agent
                    current_agent = event.new_agent.name
                    
                    print(f"\nğŸ”„ ãƒãƒ³ãƒ‰ã‚ªãƒ• {handoff_count}: {old_agent} â†’ {current_agent}")
                    
                elif event.type == "run_item_stream_event":
                    item = event.item
                    
                    if item.type == "tool_call_item":
                        tool_name = StreamingEventAnalyzer()._safe_tool_name(item)
                        print(f"\nğŸ”§ [{current_agent}] {tool_name} å®Ÿè¡Œ")
                        
                    elif item.type == "tool_call_output_item":
                        print(f"âœ… [{current_agent}] ãƒ„ãƒ¼ãƒ«å®Œäº†")
                        
                    elif "handoff" in item.type:
                        print(f"ğŸš€ [{current_agent}] ãƒãƒ³ãƒ‰ã‚ªãƒ•å‡¦ç†")
            
            print(f"\nğŸ“Š ãƒãƒ³ãƒ‰ã‚ªãƒ•çµ±è¨ˆ:")
            print(f"   é–‹å§‹Agent: {coordinator_agent.name}")
            print(f"   æœ€çµ‚Agent: {current_agent}")
            print(f"   ãƒãƒ³ãƒ‰ã‚ªãƒ•å›æ•°: {handoff_count}")
            print(f"   å‡¦ç†æ™‚é–“: {analyzer.get_summary()['execution_time']:.2f}ç§’")
            
            # æœ€çµ‚çµæœ
            final_result = streaming_result.final_output
            if final_result:
                print(f"ğŸ’¬ æœ€çµ‚çµæœ: {final_result}")
                
        except Exception as e:
            print(f"âŒ ãƒãƒ³ãƒ‰ã‚ªãƒ•ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")


async def demonstrate_custom_streaming_ui(user_context: UserContext):
    """ã‚«ã‚¹ã‚¿ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°UIãƒ‡ãƒ¢"""
    print("\n" + "="*80)
    print("ğŸ¨ 4. ã‚«ã‚¹ã‚¿ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°UIãƒ‡ãƒ¢")
    print("="*80)
    
    # UIãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªAgent
    ui_agent = Agent[UserContext](
        name="UI-Friendly Agent",
        instructions=(
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«æœ€é©åŒ–ã•ã‚ŒãŸã€"
            "æ®µéšçš„ã§è¦–è¦šçš„ã«åˆ†ã‹ã‚Šã‚„ã™ã„å¿œç­”ã‚’æä¾›ã—ã¾ã™ã€‚"
            "é€²è¡ŒçŠ¶æ³ã‚’æ˜ç¢ºã«ç¤ºã—ã€çµæœã‚’æ§‹é€ åŒ–ã—ã¦è¡¨ç¤ºã—ã¾ã™ã€‚"
        ),
        model="gpt-4o-mini",
        tools=[search_knowledge_base, generate_random_number, get_current_time],
        output_type=AgentOutputSchema(StreamingResponse, strict_json_schema=False),
    )
    
    test_input = "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å­¦ç¿’ã«ã¤ã„ã¦èª¿ã¹ã¦ã€å­¦ç¿’è¨ˆç”»ã‚’ç«‹ã¦ã¦ãã ã•ã„"
    
    try:
        print(f"ğŸ“ UIæœ€é©åŒ–ã‚¯ã‚¨ãƒª: ã€Œ{test_input}ã€")
        print("ğŸ¨ ã‚«ã‚¹ã‚¿ãƒ UIè¡¨ç¤ºé–‹å§‹...")
        print("="*80)
        
        streaming_result = Runner.run_streamed(
            starting_agent=ui_agent,
            input=test_input,
            context=user_context,
            max_turns=5
        )
        
        # UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé¢¨ã®è¡¨ç¤º
        ui_state = {
            "current_phase": "åˆæœŸåŒ–ä¸­...",
            "progress": 0,
            "generated_text": "",
            "tool_results": [],
            "status": "é€²è¡Œä¸­"
        }
        
        total_expected_events = 50  # æ¦‚ç®—
        event_count = 0
        
        print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚ ğŸ¤– AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†                                        â”‚")
        print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        
        async for event in streaming_result.stream_events():
            event_count += 1
            progress = min(100, (event_count / total_expected_events) * 100)
            ui_state["progress"] = progress
            
            if event.type == "raw_response_event":
                if isinstance(event.data, ResponseTextDeltaEvent) and event.data.delta:
                    ui_state["generated_text"] += event.data.delta
                    ui_state["current_phase"] = "ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆä¸­..."
                    
                    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼é¢¨è¡¨ç¤º
                    bar_length = 30
                    filled = int(bar_length * progress / 100)
                    bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
                    print(f"\râ”‚ ğŸ“Š é€²è¡ŒçŠ¶æ³: [{bar}] {progress:5.1f}% - {ui_state['current_phase']:<20} â”‚", end="", flush=True)
                    
            elif event.type == "run_item_stream_event":
                item = event.item
                
                if item.type == "tool_call_item":
                    tool_name = StreamingEventAnalyzer()._safe_tool_name(item)
                    ui_state["current_phase"] = f"ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ: {tool_name}"
                    print(f"\nâ”‚ ğŸ”§ {tool_name} ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™...                                      â”‚")
                    
                elif item.type == "tool_call_output_item":
                    tool_name = getattr(getattr(item, 'raw_item', None), 'name', None) or getattr(item, 'tool_name', 'Unknown')
                    ui_state["tool_results"].append({
                        "name": tool_name,
                        "output": item.output[:60] + "..." if len(item.output) > 60 else item.output
                    })
                    ui_state["current_phase"] = "ãƒ„ãƒ¼ãƒ«çµæœå‡¦ç†ä¸­..."
                    print(f"â”‚ âœ… ãƒ„ãƒ¼ãƒ«å®Œäº†: {item.output[:50]}{'...' if len(item.output) > 50 else '':<50} â”‚")
                    
                elif item.type == "message_output_item":
                    ui_state["current_phase"] = "å¿œç­”å®Œæˆ"
                    print(f"â”‚ ğŸ’¬ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆå®Œäº†                                                      â”‚")
        
        # æœ€çµ‚UIè¡¨ç¤º
        ui_state["status"] = "å®Œäº†"
        ui_state["progress"] = 100
        
        print(f"\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print(f"â”‚ ğŸ‰ å‡¦ç†å®Œäº†! ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {ui_state['status']:<55} â”‚")
        print(f"â”‚ ğŸ“Š ä½¿ç”¨ãƒ„ãƒ¼ãƒ«æ•°: {len(ui_state['tool_results']):<60} â”‚")
        print(f"â”‚ ğŸ“ ç”Ÿæˆæ–‡å­—æ•°: {len(ui_state['generated_text']):<58} â”‚")
        print(f"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        
        # æœ€çµ‚çµæœã®æ•´ç†è¡¨ç¤º
        final_result = streaming_result.final_output
        if final_result:
            print(f"\nğŸ“‹ æœ€çµ‚å‡ºåŠ›:")
            if hasattr(final_result, 'content'):
                print(f"   {final_result.content}")
            else:
                print(f"   {final_result}")
                
    except Exception as e:
        print(f"\nâŒ ã‚«ã‚¹ã‚¿ãƒ UIã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    # API ã‚­ãƒ¼ã®ç¢ºèª
    if not check_api_key():
        sys.exit(1)
    
    try:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä½œæˆ
        user_context = UserContext(
            user_id="streaming_user_001",
            session_id="streaming_session_456",
            preferences={
                "ui_mode": "detailed",
                "streaming_speed": "normal",
                "show_progress": True
            }
        )
        
        print("ğŸª OpenAI Agents SDK - Streaming å„è¦ç´  ãƒ‡ãƒ¢")
        print("="*80)
        print(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {user_context.user_id}")
        print(f"ğŸ”— ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {user_context.session_id}")
        print(f"âš™ï¸ è¨­å®š: {user_context.preferences}")
        print("="*80)
        
        # 1. åŸºæœ¬çš„ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢
        #await demonstrate_basic_streaming(user_context)
        
        # 2. é«˜åº¦ãªãƒ„ãƒ¼ãƒ«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢
        #await demonstrate_advanced_streaming_with_tools(user_context)
        
        # 3. ãƒãƒ³ãƒ‰ã‚ªãƒ•ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢
        await demonstrate_handoff_streaming(user_context)
        
        # 4. ã‚«ã‚¹ã‚¿ãƒ UIã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢
        #await demonstrate_custom_streaming_ui(user_context)
        
        print(f"\nğŸ‰ å…¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†ï¼")
        print("="*80)
        print("ğŸ“š å­¦ç¿’å†…å®¹ã¾ã¨ã‚:")
        print("âœ… Runner.run_streamed() - ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œ")
        print("âœ… RawResponsesStreamEvent - ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ")
        print("âœ… RunItemStreamEvent - å®Œäº†å˜ä½ã‚¤ãƒ™ãƒ³ãƒˆ")
        print("âœ… AgentUpdatedStreamEvent - Agentå¤‰æ›´ã‚¤ãƒ™ãƒ³ãƒˆ")
        print("âœ… ItemHelpers - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æŠ½å‡ºãƒ˜ãƒ«ãƒ‘ãƒ¼")
        print("âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ†æãƒ»çµ±è¨ˆ")
        print("âœ… ã‚«ã‚¹ã‚¿ãƒ UIå®Ÿè£…")
        print("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º")
        print("="*80)
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e).__name__}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())